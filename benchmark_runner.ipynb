{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is faster to import benchmark as a python package once to run multiple benchmarks\n",
    "\n",
    "import benchmark\n",
    "\n",
    "import sys\n",
    "sys.argv = sys.argv[:1]\n",
    "\n",
    "benchmark.make_tensor_proto([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(np.array([[1,2,3], [3,3]])).ravel().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.make_tensor_proto([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.FLAGS.model_name='default'\n",
    "benchmark.FLAGS.signature_name='predict'\n",
    "benchmark.FLAGS.port=8500\n",
    "benchmark.FLAGS.input_name='input_example_tensor'\n",
    "benchmark.FLAGS.tfrecord_dataset_path='/usr/local/google/home/alekseyv/snap/ai-platform-benchmarks/data/data-00-of-09.tfrecord'\n",
    "benchmark.FLAGS.qps_range='[100,150,200]'\n",
    "benchmark.FLAGS.num_requests=200\n",
    "benchmark.FLAGS.batch_size=400 \n",
    "benchmark.FLAGS.csv_report_filename='report.csv' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "benchmark.FLAGS.num_requests=1\n",
    "benchmark.FLAGS.port=8500\n",
    "benchmark.FLAGS.mode='grpc'\n",
    "benchmark.FLAGS.qps_range='[10]'\n",
    "benchmark.FLAGS.workers = 1\n",
    "benchmark.main('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "!/bin/python3 ./benchmark.py \\\n",
    "    --model_name='default' \\\n",
    "    --signature_name='predict' \\\n",
    "    --port=8500 \\\n",
    "    --input_name='input_example_tensor' \\\n",
    "    --tfrecord_dataset_path='/usr/local/google/home/alekseyv/snap/ai-platform-benchmarks/data/data-00-of-09.tfrecord' \\\n",
    "    --qps_range='[10,30,40,50,55,60,65,70]' \\\n",
    "    --num_requests=500 \\\n",
    "    --workers=5 \\\n",
    "    --batch_size=400 \\\n",
    "    --csv_report_filename='benchmark_qps_grte.csv' \\\n",
    "    --mode='grpc' \\\n",
    "    --distribution='uniform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2020-11-25 11:28:53.234058: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "WARNING:tensorflow:From /usr/local/google/home/alekseyv/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "W1125 11:28:54.022553 140198545741632 deprecation.py:317] From /usr/local/google/home/alekseyv/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "INFO:tensorflow:ModelServer at: localhost:8500\n",
      "I1125 11:28:54.022812 140198545741632 benchmark.py:667] ModelServer at: localhost:8500\n",
      "INFO:tensorflow:Loading data\n",
      "I1125 11:28:54.022874 140198545741632 benchmark.py:669] Loading data\n",
      "INFO:tensorflow:loading data for prediction\n",
      "I1125 11:28:54.022930 140198545741632 benchmark.py:474] loading data for prediction\n",
      "2020-11-25 11:28:54.144877: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2020-11-25 11:28:54.147719: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2020-11-25 11:28:54.147757: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: alekseyv3.kir.corp.google.com\n",
      "2020-11-25 11:28:54.147764: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: alekseyv3.kir.corp.google.com\n",
      "2020-11-25 11:28:54.147877: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 440.100.0\n",
      "2020-11-25 11:28:54.147902: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 440.100.0\n",
      "2020-11-25 11:28:54.147908: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 440.100.0\n",
      "2020-11-25 11:28:54.148205: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-25 11:28:54.173674: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3699850000 Hz\n",
      "2020-11-25 11:28:54.174665: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x45c04a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-25 11:28:54.174706: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "INFO:tensorflow:Running gRPC benchmark at 10 qps\n",
      "I1125 11:28:54.403015 140198545741632 benchmark.py:192] Running gRPC benchmark at 10 qps\n",
      "INFO:tensorflow:Running gRPC benchmark at 10 qps\n",
      "I1125 11:28:54.407698 140198545741632 benchmark.py:192] Running gRPC benchmark at 10 qps\n",
      "INFO:tensorflow:Running gRPC benchmark at 10 qps\n",
      "I1125 11:28:54.413902 140198545741632 benchmark.py:192] Running gRPC benchmark at 10 qps\n",
      "INFO:tensorflow:Running gRPC benchmark at 10 qps\n",
      "I1125 11:28:54.422437 140198545741632 benchmark.py:192] Running gRPC benchmark at 10 qps\n",
      "INFO:tensorflow:Running gRPC benchmark at 10 qps\n",
      "I1125 11:28:54.428717 140198545741632 benchmark.py:192] Running gRPC benchmark at 10 qps\n",
      "INFO:tensorflow:reqested_qps: 50\tactual_qps: 25.47\tsuccess: 250\terror: 0\ttime: 9.81\tavg_latency: 4913.61\tp50: 5179.55\tp90: 7166.62\tp99: 7759.26\tavg_miss_rate_percent: 0.00\n",
      "I1125 11:29:04.239782 140198545741632 benchmark.py:655] reqested_qps: 50\tactual_qps: 25.47\tsuccess: 250\terror: 0\ttime: 9.81\tavg_latency: 4913.61\tp50: 5179.55\tp90: 7166.62\tp99: 7759.26\tavg_miss_rate_percent: 0.00\n",
      "INFO:tensorflow:\n",
      " reqested_qps  actual_qps  success  error  avg_latency          p99  avg_miss_rate_percent\n",
      "           50    25.47126      250      0   4913.61198  7759.264534                    0.0\n",
      "I1125 11:29:04.255713 140198545741632 benchmark.py:741] \n",
      " reqested_qps  actual_qps  success  error  avg_latency          p99  avg_miss_rate_percent\n",
      "           50    25.47126      250      0   4913.61198  7759.264534                    0.0\n"
     ]
    }
   ],
   "source": [
    "!/bin/python3 ./benchmark.py \\\n",
    "    --model_name='default' \\\n",
    "    --signature_name='predict' \\\n",
    "    --port=8500 \\\n",
    "    --input_name='input_example_tensor' \\\n",
    "    --tfrecord_dataset_path='/usr/local/google/home/alekseyv/snap/ai-platform-benchmarks/data/data-00-of-09.tfrecord' \\\n",
    "    --qps_range='[10]' \\\n",
    "    --num_requests=50 \\\n",
    "    --workers=1 \\\n",
    "    --batch_size=40 \\\n",
    "    --csv_report_filename='temp.csv' \\\n",
    "    --mode='grpc' \\\n",
    "    --distribution='uniform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "70af468c1a10\n"
     ]
    }
   ],
   "source": [
    "!docker container kill $(docker ps -q)"
    "import benchmark\n",
    "\n",
    "import sys\n",
    "sys.argv = sys.argv[:1]\n",
    "\n",
    "benchmark.FLAGS.model_name='default'\n",
    "benchmark.FLAGS.signature_name='predict'\n",
    "\n",
    "jsonl_file_path = '/home/jupyter/snap/model_v2/data/data_1.json'\n",
    "string_proto = ''\n",
    "row_dict = {}\n",
    "request = None\n",
    "with open(jsonl_file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        row_dict = eval(line)\n",
    "        request = benchmark.generate_grpc_request_from_dictionary2(row_dict)\n",
    "        #string_proto = str(request)\n",
    "        #print(string_proto)\n",
    "        print(request.inputs[\"user_profile__app_purchase_aic_3011_days_since_last_event_log:0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 8500:8500 -p 8501:8501 \\\n",
    "  --mount type=bind,source='/usr/local/google/home/alekseyv/snap/ai-platform-benchmarks-modified/',target=/models/default \\\n",
    "  -e MODEL_NAME=default -t tensorflow/serving:2.3.0"
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059\\x1e8Q=O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059\\xd6U\\x1b?O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059O\\x12\\x059'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(row_dict[\"user_profile__app_purchase_aic_3011_days_since_last_event_log:0\"], dtype=np.float32).tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
